"""ë™êµ­ëŒ€ ì§ì› ì—°ë½ì²˜ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ì¼íšŒì„± Selenium í¬ë¡¤ëŸ¬ì…ë‹ˆë‹¤."""
from __future__ import annotations

import time
import warnings
from pathlib import Path

import pandas as pd
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.support.ui import WebDriverWait
from tqdm import tqdm

warnings.filterwarnings("ignore")

TARGET_URL = "https://www.dongguk.edu/staff/list"
OUTPUT_PATH = Path("./data/dongguk_staff_contacts.csv")


def build_driver() -> webdriver.Chrome:
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    return webdriver.Chrome(options=chrome_options)


def expand_all_nodes(driver) -> None:
    """ëª¨ë“  íŠ¸ë¦¬ë¥¼ ì¬ê·€ì ìœ¼ë¡œ(ë°˜ë³µì ìœ¼ë¡œ) í¼ì¹©ë‹ˆë‹¤."""
    print("ğŸŒ³ íŠ¸ë¦¬ ë©”ë‰´ í¼ì¹˜ê¸° ì‹œì‘...")
    max_depth = 20 # ë¬´í•œ ë£¨í”„ ë°©ì§€
    for _ in range(max_depth):
        # ë‹«í˜€ìˆëŠ” ë…¸ë“œì˜ 'í¼ì¹˜ê¸° ì•„ì´ì½˜' ì°¾ê¸° (li.jstree-closed ì§ê³„ ìì‹ i.jstree-ocl)
        closed_icons = driver.find_elements(By.CSS_SELECTOR, "li.jstree-closed > i.jstree-ocl")
        
        if not closed_icons:
            print("âœ¨ ëª¨ë“  íŠ¸ë¦¬ê°€ í¼ì³ì¡ŒìŠµë‹ˆë‹¤.")
            break
        
        print(f"ğŸ“‚ {len(closed_icons)}ê°œì˜ ë‹«íŒ í´ë”ë¥¼ í¼ì¹©ë‹ˆë‹¤...")
        for icon in closed_icons:
            try:
                # í™”ë©´ì— ì•ˆ ë³´ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ JSë¡œ í´ë¦­
                driver.execute_script("arguments[0].click();", icon)
                time.sleep(0.05) 
            except Exception:
                pass
        
        time.sleep(1.0) # DOM ì—…ë°ì´íŠ¸ ëŒ€ê¸°


def crawl_staff_contacts() -> pd.DataFrame:
    driver = build_driver()
    driver.get(TARGET_URL)
    wait = WebDriverWait(driver, 20)

    try:
        time.sleep(3.0)
        # íŠ¸ë¦¬ ì˜ì—­ ëŒ€ê¸°
        wait.until(EC.presence_of_element_located((By.ID, "tree")))
    except Exception as exc:
        driver.quit()
        raise RuntimeError("ë¶€ì„œ íŠ¸ë¦¬(#tree)ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.") from exc

    # 1. íŠ¸ë¦¬ ëª¨ë‘ í¼ì¹˜ê¸°
    expand_all_nodes(driver)

    data: list[list[str]] = []
    
    # 2. ëª¨ë“  ë¶€ì„œ ë§í¬ ìˆ˜ì§‘
    # íŠ¸ë¦¬ê°€ ë‹¤ í¼ì³ì¡Œìœ¼ë¯€ë¡œ ëª¨ë“  ì•µì»¤ íƒœê·¸ë¥¼ ê°€ì ¸ì˜´
    dept_links = driver.find_elements(By.CSS_SELECTOR, "#tree a.jstree-anchor")
    print(f"ì´ {len(dept_links)}ê°œì˜ ë¶€ì„œ ë§í¬ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

    # 3. ìˆœíšŒí•˜ë©° ë°ì´í„° ìˆ˜ì§‘
    for index in tqdm(range(len(dept_links)), desc="ë¶€ì„œë³„ ë°ì´í„° ìˆ˜ì§‘"):
        try:
            # DOMì´ ë³€ê²½ë˜ì—ˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë‹¤ì‹œ ì°¾ì•„ì„œ ì¸ë±ìŠ¤ë¡œ ì ‘ê·¼ (ì•ˆì „í•œ ë°©ë²•)
            current_links = driver.find_elements(By.CSS_SELECTOR, "#tree a.jstree-anchor")
            if index >= len(current_links):
                break
            
            link = current_links[index]
            dept_name = link.text.strip()
            
            # í´ë¦­í•˜ì—¬ í…Œì´ë¸” ë¡œë“œ
            driver.execute_script("arguments[0].click();", link)
            time.sleep(0.8) # ë°ì´í„° ë¡œë”© ëŒ€ê¸°

            # í…Œì´ë¸” ë°ì´í„° ìˆ˜ì§‘
            rows = driver.find_elements(By.CSS_SELECTOR, "table tbody tr")
            
            if not rows:
                continue

            for row in rows:
                # "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤" ê°™ì€ ì•ˆë‚´ ë©”ì‹œì§€ ì œì™¸
                if "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤" in row.text:
                    continue

                cols = [cell.text.strip() for cell in row.find_elements(By.TAG_NAME, "td")]
                
                # ìœ íš¨í•œ ë°ì´í„° í–‰ì¸ì§€ í™•ì¸ (ìµœì†Œ 2ê°œ ì´ìƒ ì»¬ëŸ¼ ë“±)
                if len(cols) >= 2:
                    # ë¶€ì„œëª…(íŠ¸ë¦¬ì—ì„œ í´ë¦­í•œ ì´ë¦„)ì„ ì²« ë²ˆì§¸ ì»¬ëŸ¼ìœ¼ë¡œ ì¶”ê°€í•˜ì—¬ ì €ì¥
                    # colsê°€ [ì´ë¦„, ë‹´ë‹¹ì—…ë¬´, ì „í™”ë²ˆí˜¸, ...] í˜•íƒœë¼ê³  ê°€ì • ì‹œ
                    # ë§Œì•½ í…Œì´ë¸” ì•ˆì— ë¶€ì„œëª…ì´ ì—†ë‹¤ë©´ dept_nameì„ í™œìš©
                    
                    # ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœí•˜ê²Œ [íŠ¸ë¦¬ë¶€ì„œëª…] + [í…Œì´ë¸”ì»¬ëŸ¼ë“¤...] ë¡œ ì €ì¥
                    data.append([dept_name] + cols)

        except Exception as e:
            # íŠ¹ì • ë¶€ì„œ ìˆ˜ì§‘ ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰
            # print(f"âš ï¸ '{dept_name}' ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
            pass

    driver.quit()
    print("âœ… í¬ë¡¤ë§ ì™„ë£Œ ë° ë¸Œë¼ìš°ì € ì¢…ë£Œ.")

    # ë°ì´í„°í”„ë ˆì„ ìƒì„±
    # ì»¬ëŸ¼ëª…ì€ ì‹¤ì œ ë°ì´í„° êµ¬ì¡°ì— ë”°ë¼ ì¡°ì • í•„ìš”. ë™ì ìœ¼ë¡œ ìƒì„±.
    if data:
        max_cols = max(len(row) for row in data)
        columns = ["ì¡°ì§(íŠ¸ë¦¬)"] + [f"Data_{i}" for i in range(max_cols - 1)]
        # ì¼ë°˜ì ì¸ ì˜ˆìƒ ì»¬ëŸ¼: ì¡°ì§, ì§ìœ„, ì„±ëª…, ë‹´ë‹¹ì—…ë¬´, ì „í™”ë²ˆí˜¸, ì´ë©”ì¼ ë“±
        # í•„ìš”ì‹œ columns = ["ì¡°ì§", "ì§ìœ„", "ì„±ëª…", "ë‹´ë‹¹ì—…ë¬´", "ì „í™”ë²ˆí˜¸", "ì´ë©”ì¼"] ë“±ìœ¼ë¡œ ê³ ì • ê°€ëŠ¥
        
        df = pd.DataFrame(data, columns=columns)
        df.drop_duplicates(inplace=True)
    else:
        df = pd.DataFrame()

    return df


def main() -> None:
    df = crawl_staff_contacts()
    df.to_csv(OUTPUT_PATH, index=False, encoding="utf-8-sig")
    print(f"ì´ {len(df)}ê±´ì˜ ë°ì´í„° ì €ì¥ ì™„ë£Œ! ({OUTPUT_PATH.resolve()})")


if __name__ == "__main__":
    main()
